<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8" />
		<title>three-vrm example</title>
    <script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"
		/>
		<style>
			body {
				margin: 0;
			}
			canvas {
				display: block;
			}
		</style>
	</head>

	<body>
		<script type="importmap">
			{
				"imports": {
					"three": "https://cdn.jsdelivr.net/npm/three@0.169.0/build/three.module.js",
					"three/addons/": "https://cdn.jsdelivr.net/npm/three@0.169.0/examples/jsm/",
					"@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3/lib/three-vrm.module.js"
				}
			}
		</script>

		<script type="module">
			import * as THREE from 'three';
			import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
			import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
			import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

			// renderer
			const renderer = new THREE.WebGLRenderer({ antialias: true });
			renderer.setSize( window.innerWidth, window.innerHeight );
			renderer.setPixelRatio( window.devicePixelRatio );
			document.body.appendChild( renderer.domElement );

			// camera
			const camera = new THREE.PerspectiveCamera( 30.0, window.innerWidth / window.innerHeight, 0.1, 20.0 );
			camera.position.set( 0.05, 1.4, 1.1 );

			// camera controls
			const controls = new OrbitControls( camera, renderer.domElement );
			controls.screenSpacePanning = true;
			controls.target.set( 0.05, 1.4, 0.0 );
			controls.update();

			// scene
			const scene = new THREE.Scene();

			// light
			const light = new THREE.DirectionalLight( 0xffffff, Math.PI );
			light.position.set( 1.0, 1.0, 1.0 ).normalize();
			scene.add( light );

			// gltf and vrm
			let currentVrm = undefined;
      let currentMixer = undefined;
			const loader = new GLTFLoader();
			loader.crossOrigin = 'anonymous';

			loader.register( ( parser ) => {

				return new VRMLoaderPlugin( parser );

			} );

			loader.load(

				// URL of the VRM you want to load
				'AvatarSample_A(1.0).vrm',

				// called when the resource is loaded
				( gltf ) => {

					const vrm = gltf.userData.vrm;

					// calling these functions greatly improves the performance
          VRMUtils.removeUnnecessaryVertices( gltf.scene );
          VRMUtils.combineSkeletons( gltf.scene );
          VRMUtils.combineMorphs( vrm );

					// Disable frustum culling
					vrm.scene.traverse( ( obj ) => {

						obj.frustumCulled = false;

					} );

					currentVrm = vrm;
          prepareAnimation(vrm);
					console.log( vrm );
					scene.add( vrm.scene );

				},

				// called while loading is progressing
				( progress ) => console.log( 'Loading model...', 100.0 * ( progress.loaded / progress.total ), '%' ),

				// called when loading has errors
				( error ) => console.error( error )

			);

      const textureLoader = new THREE.TextureLoader();
      textureLoader.load('./test_bg.jpg', (texture) => {
        scene.background = texture;
      });

      function prepareAnimation( vrm ) {

          currentMixer = new THREE.AnimationMixer( vrm.scene );

          const quatA = new THREE.Quaternion( 0.0, 0.0, 0.0, 1.0 );
          const quatB = new THREE.Quaternion( 0.0, 0.0, 0.0, 1.0 );
          const quatC = new THREE.Quaternion( 0.0, 0.0, 0.0, 1.0 );
          quatB.setFromEuler( new THREE.Euler( -0.01 * Math.PI, 0.0, 0.0 ) );
          quatC.setFromEuler( new THREE.Euler( 0.01 * Math.PI, 0.0, 0.0 ) );

          const spineTrack = new THREE.QuaternionKeyframeTrack(
              vrm.humanoid.getNormalizedBoneNode( 'spine' ).name + '.quaternion', // name
              [ 0.0, 0.25, 0.5, 0.75, 1.0 ], // times
              [ ...quatA.toArray(), ...quatB.toArray(), ...quatA.toArray(), ...quatC.toArray(), ...quatA.toArray() ] // values
          );

          const neckTrack = new THREE.QuaternionKeyframeTrack(
              vrm.humanoid.getNormalizedBoneNode( 'neck' ).name + '.quaternion', // name
              [ 0.0, 0.25, 0.5, 0.75, 1.0 ], // times
              [ ...quatA.toArray(), ...quatC.toArray(), ...quatA.toArray(), ...quatB.toArray(), ...quatA.toArray() ] // values
          );

          const blinkTrack = new THREE.NumberKeyframeTrack(
              vrm.expressionManager.getExpressionTrackName( 'blink' ), // name
              [ 0.0, 0.96, 0.98, 1.0 ], // times
              [ 0.0, 0.0, 1.0, 0.0 ] // values
          );

          const clip = new THREE.AnimationClip( 'Animation', 1.0, [ spineTrack, neckTrack, blinkTrack ] );
          const action = currentMixer.clipAction( clip );
          action.timeScale = 2.0;
          action.play();

      }

      // document.getElementById("playAudio").addEventListener("click", async () => {
      //   if (!audioContext) {
      //     audioContext = new (window.AudioContext || window.webkitAudioContext)();
      //   }

      //   try {
      //     await loadAudio(result.audioPath);
      //     animate();
      //     document.getElementById("playAudio").style.display = "none"; // Hide button after starting
      //   } catch (error) {
      //     console.error("Audio loading failed:", error);
      //   }
      // });
      
      let analyser, dataArray;
      let audioContext;
      let expression = "Neutral";
      let audioPath = undefined;
      let isPlaying = false;
      let waiting = false;

      async function loadAudio(filePath) {
        const response = await fetch(filePath);
        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        source.connect(analyser);
        analyser.connect(audioContext.destination);

        source.start();
        console.log("Audio started");
      }

      const socket = io.connect('http://localhost:5000');
      socket.on('data_response', async data => {
        console.log('Received data:', data);
        // audioPath = data.audioPath;
        expression = data.text;
        console.log("Path: ", data.audioPath);

        waiting = true;
        await playAudio(data.audioPath);
        // await playAudio("/audio.wav");
        // document.getElementById('text').innerText = expression;
      });

      async function playAudio(filePath) {
        if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        try {
        const response = await fetch(filePath);
        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        source.connect(analyser);
        analyser.connect(audioContext.destination);
        
        isPlaying = true;

        source.start();
        console.log('Audio started');

        source.onended = () => {
          console.log('Audio finished');
          isPlaying = false;
          waiting = false;
          socket.emit('audio_complete');
          // socket.emit('request_data');
        };}
        catch (error) {
          console.log("No audio file / error")
          // socket.emit('request_data');
        }
      }

      // if (!waiting) {
      //   socket.emit('request_data');
      // } 

      // if (!waiting) {
      //   socket.emit('request_data');
      // }

      // Load audio and get analyser
      // loadAudio("./output/audio.wav").then((audioData) => {
      //     analyser = audioData.analyser;
      //     dataArray = audioData.dataArray;
      // });


			// helpers
			// const gridHelper = new THREE.GridHelper( 10, 10 );
			// scene.add( gridHelper );

			// const axesHelper = new THREE.AxesHelper( 5 );
			// scene.add( axesHelper );

			// animate
			const clock = new THREE.Clock();
			clock.start();

			function animate() {

				requestAnimationFrame( animate );

				// update vrm components
				if ( currentVrm ) {
                    
          const s = Math.sin( Math.PI * clock.elapsedTime * 0.5 );
          currentVrm.scene.position.set( 0, 0.003*s, 0 )
                    
          currentVrm.humanoid.getNormalizedBoneNode( 'leftUpperArm' ).rotation.z = -1;
          currentVrm.humanoid.getNormalizedBoneNode( 'rightUpperArm' ).rotation.z = 1;
          
          if(expression) {
            switch (expression) {
              case "Happy":
                currentVrm.expressionManager.setValue('happy', 1.0);
                currentVrm.expressionManager.setValue('relaxed', 0.0);
                currentVrm.expressionManager.setValue('sad', 0.15);
                currentVrm.expressionManager.setValue('angry', 0.0);
                currentVrm.expressionManager.setValue('surprised', 0.0);                
                break;
              case "Sad":
                currentVrm.expressionManager.setValue('happy', 0.0);
                currentVrm.expressionManager.setValue('relaxed', 0.0);
                currentVrm.expressionManager.setValue('sad', 1.0);
                currentVrm.expressionManager.setValue('angry', 0.25);
                currentVrm.expressionManager.setValue('surprised', 0.0);                
                break;
              case "Angry":
                currentVrm.expressionManager.setValue('happy', 0.0);
                currentVrm.expressionManager.setValue('relaxed', 0.0);
                currentVrm.expressionManager.setValue('sad', 0.0);
                currentVrm.expressionManager.setValue('angry', 1.0);
                currentVrm.expressionManager.setValue('surprised', 0.0);                
                break;
              case "Excited":
                currentVrm.expressionManager.setValue('happy', 1.0);
                currentVrm.expressionManager.setValue('relaxed', 1.0);
                currentVrm.expressionManager.setValue('sad', 0.0);
                currentVrm.expressionManager.setValue('angry', 0.0);
                currentVrm.expressionManager.setValue('surprised', 0.5);                
                break;
              case "Surprised":
                currentVrm.expressionManager.setValue('happy', 0.0);
                currentVrm.expressionManager.setValue('relaxed', 0.0);
                currentVrm.expressionManager.setValue('sad', 0.0);
                currentVrm.expressionManager.setValue('angry', 0.0);
                currentVrm.expressionManager.setValue('surprised', 1.0);                
                break;
            
              default:
                currentVrm.expressionManager.setValue('happy', 0.0);
                currentVrm.expressionManager.setValue('relaxed', 0.4);
                currentVrm.expressionManager.setValue('sad', 0.0);
                currentVrm.expressionManager.setValue('angry', 0.0);
                currentVrm.expressionManager.setValue('surprised', 0.0); 
                break;
            }
          }

          if(analyser) {
            analyser.getByteTimeDomainData(dataArray);
        
            // Compute loudness as the average of the frequency data
            // let loudness = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
            // loudness = (loudness - 128) / 255; // Normalize between 0 and 1
            let max = 0;
            let min = 255;
            for(let i = 1; i < dataArray.length; i++) {
              max = Math.max(max, dataArray[i]);
              min = Math.min(min, dataArray[i]);
            }
            //console.log(dataArray[10]);

            
            // Apply loudness to mouth opening expression
            currentVrm.expressionManager.setValue('aa', max/200.0);
            currentVrm.expressionManager.setValue('aa', min/200.0);
            currentVrm.expressionManager.setValue('ee', max/200.0);
            currentVrm.expressionManager.setValue('ee', min/200.0);
            if(max-min < 10) {
              currentVrm.expressionManager.setValue('aa', 0.0);
              currentVrm.expressionManager.setValue('ee', 0.0);
            }
          }

					currentVrm.update( clock.getDelta() );

				}

        if ( currentMixer ) {

            currentMixer.update( clock.getDelta() );

        }

				// render
				renderer.render( scene, camera );
			}

			animate();
		</script>
	</body>
</html>